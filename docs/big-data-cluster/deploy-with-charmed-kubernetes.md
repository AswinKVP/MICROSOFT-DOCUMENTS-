---
title: Deploy on Charmed Kubernetes
titleSuffix: SQL Server Big Data Clusters
description: How to deploy Microsoft Big Data Clusters on Charmed Kubernetes
author: evilnick
ms.topic: conceptual
ms.prod: sql
ms.technology: big-data-cluster
---

# Deploy [!INCLUDE[big-data-clusters-2019](../includes/ssbigdataclusters-ss-nover.md)] on Charmed Kubernetes

[!INCLUDE[SQL Server 2019](../includes/applies-to-version/sqlserver2019.md)]

This article explains how to deploy a SQL Server Big Data Cluster (BDC) on [Charmed Kubernetes][]. 

## Pre-requisites

-   **[Juju][]**: Juju is a tool which provides full automation of software deployments and operations. **Charmed Kubernetes** uses Juju to deploy, configure and operate the applications which combine to make a running Kubernetes cluster. Juju is available for Ubuntu, Windows 10, macOS and various Linux variants.
    -   Ubuntu 18.04+: Run the command: `sudo snap install juju --classic`
    -   Windows 10: Download and run the installer [here][juju-win].
    -   For macOS and non-Ubuntu Linux systems, see the [install documentation][juju-install-docs].      
-   An SSH keypair: Juju expects an SSH keypair for secure communication between the client and any units deployed. Almost all Linux distributions automatically generate SSH keys when installed. Windows 10 and Windows Server both now include the [OpenSSH][] software used to manage and use SSH keys, but a key must be generated by running the command `ssh-keygen` (more details [here][ssh-keygen]).
-   Cloud Credentials: Juju can operate and manage applications on a variety of hardware as well as major public clouds including Azure, AWS, Google, OpenStack, VMWare. To access these clouds it will be necessary to supply Juju with the appropriate credentials. This can be as simple as running the command:
`juju add-credential azure` 
and following the interactive prompt. For the purposes of this document we will assume an Azure public cloud, noting where there may be differences. For more details on credentials and using Juju with different clouds, see the [Juju documentation][juju-docs-credentials].
-   The `azdata` command line tool to bootstrap and manage the big data cluster. See the separate [install documentation here][azdata-install].
-   The `kubectl` command line tool, to access the Kubernetes cluster. On Ubuntu 18.04+, this can be installed with the command `sudo snap install kubectl -classic`. For other platforms see the [kubectl install documentation][].

  

## Deploy Charmed Kubernetes

Deploying the applications which make up **Charmed Kubernetes** is achieved with the use of Juju.

### Create a controller

> [!TIP]
> Altrenatively, you can use a hosted controller by registering at [jaas.ai](https://jaas.ai)  


Juju requires a machine or instance to act as a controller. This controller will then manage the deployment of applications and further provisioning of resources in the cloud. To create a controller, use the `juju bootstrap command`. For example, to create a new controller in the `ukwest` region of Microsoft Azure, with the name `azk8s`, run the following:

```bash
juju bootstrap azure/ukwest azk8s
```

> [!TIP]
> Creating the controller may take a few minutes. Juju will provision a new machine, install the controller agent, and check to make sure the local client can connect to it. 

### Add a model

A Juju controller can host many models (sets of applications). You can view the current models by entering the command:

```bash
juju models
```

The controller model is only used for applications specific to controller operation. Additional models can be created, and it is recommended to create a new one for each project. To add a new model called `ckbdc` run the following:

```bash
juju add-model ckbdc
```


### Configure deployment

There are two charm bundles associated with Charmed Kubernetes, these are:
-   `charmed-kubernetes`
-   `kubernetes-core`

Both represent a complete install of a Kubernetes cluster, but while the first is intended as the basis of a full production cluster with the various components running on their own machines and with multiple master and worker units, the second is a minimalist version which requires just two machines and co-locates many applications on one of them. This bundle is more suitable as the basis for testing and more customised deployments. Either version can be used to run the SQL BDC, but as it has some specific requirements the `kubernetes-core` bundle is easier to adapt and is more economical.

The system requirements of the SQL BDC specify the node it is run on should have:
-   8 vCPUs
-   64GB RAM
-   100GB storage

An 'overlay' file can be created for the `kubernetes-core` bundle to request that the kubernetes-worker machine has at least these requirements. An overlay is simply an additional YAML file which is merged on top of the bundle before it is deployed.

The full kubernetes-core bundle YAML can be viewed [here][kubernetes-core-bundle].

In addition to the machine specs, it is also necessary to modify the configuration for the `kubernetes-master` charm to allow the `kube-api-server` to run in privilleged mode. The changes can be expressed in the following overlay:

```yaml
machines:
  '0':
    constraints: cores=2 mem=4G root-disk=16G
  '1':
    constraints: cores=8 mem=64G root-disk=100G
applications:
  kubernetes-master:
    options:
      allow-privileged: 'True'
```

This file is also available to download [here][bdc-overlay]. For this guide, the file has been named `bdc-overlay.yaml`, but obviously the file can be named anything, as long as the actual filename is used  in the deploy step below.


It will also be useful to apply an overlay specific to the cloud in use. There are many sample overlays for **Charmed Kubernetes** to facilitate integration with the underlying cloud. For example, for Azure, the [sample overlay][azure-overlay] additional installs and connects the `azure-integrator` charm, which will create an Azure based storage class and enable the cluster to use natve Azure load balancers.

Other cloud-specific overlays can be found [here][overlays].

### Deploy Charmed Kubernetes

To deploy the `kubernetes-core` bundle with the chosen overlays, use the `deploy` command and specify the overlay yaml files like this:

```bash
juju deploy cs:kubernetes-core --overlay=bdc-overlay.yaml --overlay=azure-overlay.yaml --trust
```

Juju will fetch the bundle file, apply the overlays, provision machines, deploy, configure and connect the applications reuired to create a **Charmed Kubernetes** cluster. The '--trust' option is necessary to give the Azure integrator permission to use Juju's credentials to perform operations in the cloud (setting up a storage class). 

This process is likely to take several minutes. Juju will update its status regularly in this time. To view the status as the cluster is set up, run the command:

```bash
watch juju status
```

### Fetch the k8s config file

As part of the deployment, the kubernetes master unit will generate a config file. This config is used by the `kubectl` tool to manage the cluster. We can fetch it from the Kubernetes master unit to a local machine with:

```bash
 juju scp kubernetes-master/0:config ~/.kube/config
```

> [!TIP]
> This is the default location for the kubectl configuration file for most installations, some platforms may vary. 

### Set up persistent storage

When using the overlay for popular public clouds such as Azure, AWS, Google or Openstack, a storage class will be created to access any cloud native storage options. Current storage classes can be checked by running:

```bash
kubectl get sc
```

For the Azure setup described here, this should return something like:

```bash
NAME             PROVISIONER                RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE
cdk-azure-disk   kubernetes.io/azure-disk   Delete          Immediate           false                  10m
```

> [!TIP]
> To set up additional or alternative storage, see the **Charmed Kubernetes** [storage documentation][storage].

Make a note of the name of the preferred storage class, as this will be needed in the next step.

### (Optional) Access the Kubernetes Dashboard

The Kubernetes Dashboard is a useful tool for examining the current state of the cluster and spotting any potential problems.
To access the dashboard in Charmed Kubernetes, open a new terminal and run the command:
```bash
kubectl proxy
```
While this process is running, the dashboard will be proxied to a local port:
<http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/>

To log in to the dashboard, click on the breadcrumbs on the login screen and choose the `kubectl` config file retrieved in the earlier step.


## Deploy the SQL Big Data Cluster

Now the Kubernetes cluster is ready, the next step is to generate the configuration for the BDC and deploy it.

### Create a template

The `azdata` tool is used to generate templates for the BDC deployment. The first time it is run, a prompt will appear to accept the terms of its license:

```bash 
azdata bdc config list
```

This command will list the currently installed templates. To create a new template, it is easiest to first copy an existing one:

```bash
azdata bdc config init --source aks-dev-test --target ck-bdc
```

This will create a directory called `ck-bdc` containing two files:
- control.json covers the configuration of the controller pod
- bdc.json describes the additional bdc pods

The `control.json` files should be edited to select the storage class created previously. The section of YAML detailing storage has two sections, one for "data" and one for "logs". The "className" attribute for both should be changed from `default` to `cdk-azure-disk`(or whatver storage class has been defined).

```yaml
        "storage": {
            "data": {
                "className": "cdk-azure-disk",
                "accessMode": "ReadWriteOnce",
                "size": "15Gi"
            },
            "logs": {
                "className": "cdk-azure-disk",
                "accessMode": "ReadWriteOnce",
                "size": "10Gi"
            }
```

### Run the install script

To deploy the defined SQL BDC to Kubernetes, run the command:

```bash
azdata bdc create --config-profile ck-bdc
```

Initially, the installer will ask for a username and password. This will be used to access the BDC. Then it will begin deploying the pods required. This process can take a long time. Although the `azdata` tool will report progress, it is also possible to get more fine-grained information by either viewing the Kubernetes dashboard, or opening a new shell and running:

```bash
kubectl get all -n mssql-cluster
```

The installer will return output similar to the following:

```bash
NOTE: Cluster creation can take a significant amount of time depending on
configuration, network speed, and the number of nodes in the cluster.

Starting cluster deployment.
Waiting for cluster controller to start.
Waiting for cluster controller to start.
Waiting for cluster controller to start.
Waiting for cluster controller to start.
Waiting for cluster controller to start.
Waiting for cluster controller to start.
Waiting for cluster controller to start.
Cluster controller endpoint is available at 40.81.115.206:30080.
Cluster control plane is ready. 
Storage pool is ready. 
Data pool is ready. 
Compute pool is ready. 
Master pool is ready. 
Cluster 'mssql-cluster' deployed successfully.
```

### Connect to the BDC

The `azdata` tool can be used to connect to the BDC. 

```bash
azdata login
```

When prompted, the namespace is "mssql-cluster" and the username and password are those previously entered.

Once logged in successfully, the endpoints of the various BDC services can be listed with the following command:

```bash
azdata bdc endpoint list --output table
```

...which should return output similar to the following:

```bash
Description                                             Endpoint                                                 Name               Protocol
------------------------------------------------------  -------------------------------------------------------  -----------------  ----------
Gateway to access HDFS files, Spark                     https://40.81.116.26:30443                               gateway            https
Spark Jobs Management and Monitoring Dashboard          https://40.81.116.26:30443/gateway/default/sparkhistory  spark-history      https
Spark Diagnostics and Monitoring Dashboard              https://40.81.116.26:30443/gateway/default/yarn          yarn-ui            https
Application Proxy                                       https://40.81.115.223:30778                              app-proxy          https
Management Proxy                                        https://40.81.115.73:30777                               mgmtproxy          https
Log Search Dashboard                                    https://40.81.115.73:30777/kibana                        logsui             https
Metrics Dashboard                                       https://40.81.115.73:30777/grafana                       metricsui          https
Cluster Management Service                              https://40.81.115.206:30080                              controller         https
SQL Server Master Instance Front-End                    40.81.115.239,31433                                      sql-server-master  tds
HDFS File System Proxy                                  https://40.81.116.26:30443/gateway/default/webhdfs/v1    webhdfs            https
Proxy for running Spark statements, jobs, applications  https://40.81.116.26:30443/gateway/default/livy/v1       livy               https
```

## Next steps

[Tutorial: Load sample data into a SQL Server big data cluster](tutorial-load-sample-data.md)

> [!TIP]
> To remove all the instances created by Juju, including the controller, run the command:
> `juju destroy-controller azk8s --destroy-all-models`
> This will terminate the machines and remove any other resources. It is still advisable to check via the cloud console that all resources, including storage, have been removed.

<!--LINKS-->
[Charmed Kubernetes]: https://ubuntu.com/kubernetes/docs/overview
[Juju]: https://juju.is
[ssh-keygen]: https://docs.microsoft.com/en-us/windows-server/administration/openssh/openssh_overview
[OpenSSH]: https://www.openssh.com/
[juju-win]: https://juju.is/docs/installing#heading--windows
[juju-install-docs]: https://juju.is/docs/installing
[juju-docs-credentials]: https://juju.is/docs/credentials
[azdata-install]: https://docs.microsoft.com/en-us/sql/big-data-cluster/deploy-install-azdata?view=sql-server-ver15
[kubernetes-core-bundle]: https://api.jujucharms.com/charmstore/v5/bundle/kubernetes-core/archive/bundle.yaml
[azure-overlay]: https://github.com/charmed-kubernetes/bundle/blob/master/overlays/azure-overlay.yaml
[overlays]: https://ubuntu.com/kubernetes/docs/install-manual#cloud-integration
[storage]: https://ubuntu.com/kubernetes/docs/storage
[kubectl install documentation]: https://kubernetes.io/docs/tasks/tools/install-kubectl/
[bdc-overlay]: https://raw.githubusercontent.com/charmed-kubernetes/bundle/master/overlays/bdc-overlay.yaml